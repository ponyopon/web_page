私は長期インターンシップでデータ分析から予測モデル構築、アプリケーション開発まで行うプロジェクトに参画しました。
プロジェクトの概要として、クライアントはスロットの機種を開発する企業で、機種のスペックを決める工程が属人化してきており、これを解決することが目的でした。
具体的には機種のスペックを入力とし、機種のヒットしやすさを出力とする予測モデルを構築し、構築したモデルで予測が行えるアプリケーションの納品を行っていきました。
　データ分析フェーズでは、ヒストグラムや散布図、ヒートマップなどの可視化手法を用いたり、カラム同士の相関を見て目的変数への影響をドメインの知識から仮設立てをし、モデル構築を行ったりしました。プロジェクトの課題として、クライアントがすでに用いている独自の指標があり精度が8割弱だったため機械学習を用いてより高精度な予測モデルを構築する必要がありました。主に行ったことは学習データのグルーピング分けと特徴量選択です。ヒストグラムや散布図の可視化を通して、データの分布が偏っているグループがあり、学習データをあらかじめ分割し2つのモデルを構築しました。特徴量選択にはラッソ回帰を用いました。ラッソ回帰には正則化項により特徴量重要度を見ることで特徴量選択に直接つながるという特徴があるためです。また、モデル構築では、分析やクライアントへの説明において解釈性が必要なことから決定木を用いました。過学習を抑制するため木の深さや葉に分類されるサンプル数などのハイパーパラメータも調節しました。予測方法では、クライアントから頂いているデータ数がやや少なかったのでleave-one-out cross-validationというテストデータ一件の交差検証を行い、できる限り学習データを満遍なく使用したモデルを構築しました。また、データの目的変数は連続値ではありましたが、閾値をクライアントと相談しながら2値化し、回帰ではなく2値分類にすることで問題の単純化をしています。閾値には、目的変数に時系列要素が含まれていたため、閾値を移動統計量で考えクライアントのドメイン知識と定義した閾値が認識と合っているかを相談しながら決めました。これらの結果、正解率89%という高精度を出すことができました。
　開発フェーズは現在も進行中ですが、フロントエンドはStreamlit,Reactを、バックエンドにはfastAPIを用いて開発を行っています。デプロイ環境はDockerを用いており、コードの管理はgit, git hubで行っています。開発の基本工程は、PMがissueを作成しそれぞれのissueに対してメンバーが一人ずつアサインされ、各自ブランチを切って作業を行っていきました。苦労した点として、エンドポイントのレスポンスでデータ型を定義する際に、辞書やリストで複数の変数をまとめすぎてデータ構造がわかりづらくなることを回避するため、数個の変数をもつクラスをいくつも定義することでデータ型の構造を細分化して実装したことです。
　全体を通して、わからないことがあれば目的と手段を整理し公式ドキュメントやChatGPTで問題解決を試み、それでも解決しなかった場合は、問題箇所を細分化した状態でチームメンバーに質問して解決しました。他にも、作業を始める前にタスクの背景から手段までをPMをすり合わせ作業内容を明確にしてから取り組むように意識しながら行動しました。