私は長期インターンでデータ分析からアプリケーション開発まで行うプロジェクトに参画しました。
プロジェクトで主に行ったことは、テーブルデータを機械学習や可視化手法を用いて分析をし、構築したAIで予測を行えるアプリケーションを開発しクライアントに納品することです。
　データ分析フェーズでは、ヒストグラムや散布図、ヒートマップなどの可視化手法を用いたり、カラム同士の相関を見て目的変数への影響をドメインの知識から仮設立てをし、モデル構築を行ったりしました。プロジェクトの課題として、クライアントがすでに用いている独自の指標があり精度が8割弱だったため機械学習を用いてより高精度な予測モデルを構築する必要がありました。主に行ったことは学習データのグルーピング分けと特徴量選択です。ヒストグラムや散布図の可視化を通して、データの分布が偏っているグループがあり、学習データをあらかじめ分割し2つのモデルを構築しました。特徴量選択にはラッソ回帰を用いました。ラッソ回帰には正則化項により特徴量重要度を見ることで特徴量選択に直接つながるという特徴があるためです。また、モデル構築では、高精度が狙えるLightGBMなどのモデルも選択肢にありましたが、複雑性がますことと解釈性が下がることから決定木を用いました。決定技では、過学習を抑制するため木の深さや葉に分類されるサンプル数などのハイパーパラメータを調節しました。これらの結果、正解率89%という高精度を出すことができました。苦労した点として、クライアントから頂いているデータ数がやや少なく、交差検証をするとモデルのサンプル数が減るため、代替案としてleave-one-out cross-validationというテストデータ一件の交差検証を行い、できる限り学習データを満遍なく使用したモデルを構築したことです。また、データの目的変数は連続値ではありましたが、問題の単純化のため、閾値をクライアントと相談し2値化しました。具体的には、目的変数に時系列要素が含まれていたため、閾値を移動統計量で考えクライアントのドメイン知識と定義した閾値が認識と合っているかを相談しました。
　開発フェーズは現在も進行中ですが、フロントエンドはStreamlit,Reactを、バックエンドにはfastAPIを用いて開発を行っています。デプロイ環境はDockerを用いており、コードの管理はgit, git hubで行っています。開発の基本工程は、PMがissueを作成しそれぞれのissueに対してメンバーが一人ずつアサインされ、各自ブランチを切って作業を行っていきました。苦労した点としては、エンドポイントのレスポンスでデータ型を定義する際に、辞書やリストで複数の変数をまとめすぎてデータ構造がわかりづらくなることを回避するため、数個の変数をもつクラスをいくつも定義することでデータ型の構造を細分化して実装したことです。
